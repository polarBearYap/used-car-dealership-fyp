{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64482ba",
   "metadata": {},
   "source": [
    "**Author**: Yap Jheng Khin\n",
    "\n",
    "**FYP II Title**: Used car dealership web application\n",
    "\n",
    "**Purpose**:\n",
    "1. This notebook explains:\n",
    "    - The reason that the `interventional` approach must be used in calculating SHAP value.\n",
    "2. Input: \n",
    "    - Car train and car test dataset. The <a href=\"https://colab.research.google.com/drive/1alFnJwZVOKntfmjxA0q8Rcni1irur5fn?usp=sharing\">Google Colab notebook</a> explains how the data is scraped from a website and preprocessed.\n",
    "    - Dictionaries containing the extracted tree weights for pre-trained car price models and pre-trained lead scoring models.\n",
    "    - A total of 10 dictionaries representing car price models in 10 training checkpoints.\n",
    "    - A total of 10 dictionaries representing lead scoring models in 10 training checkpoints.\n",
    "\n",
    "**Execution time**: At most 5 minutes in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5aed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from general_utils import deserialize_arf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171ca84",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce3156b",
   "metadata": {},
   "source": [
    "Ensure that the current Python interpreter path is correct. For example, if the **SHAP conda environment** is named as **arf_conda_exp_env**, the expected `sys.executable` should be C:\\Users\\User\\miniconda3\\envs\\\\**arf_conda_exp_env**\\\\python.exe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f08a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\arf_conda_exp_env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce527d45",
   "metadata": {},
   "source": [
    "Load data preprocessors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39dc0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'outputs/car_price/data_preprocessor.pkl', 'rb') as f:\n",
    "    cp_data_pp = pickle.load(f)\n",
    "\n",
    "with open(f'outputs/lead_scoring/data_preprocessor.pkl', 'rb') as f:\n",
    "    ls_data_pp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4750a68",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1679f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load car price test set\n",
    "car_test_set = pd.read_csv(f'outputs/car_price/car_test_processed.csv')\n",
    "\n",
    "# Get and preprocess car price test set\n",
    "cp_X_test = car_test_set.copy().drop(columns=['price', 'model'], axis=1)\n",
    "cp_X_test_pp = cp_data_pp.preprocess(cp_X_test)\n",
    "\n",
    "# Load car price test subsample to initialize explainer that uses interventional approach\n",
    "cp_X_test_truth_av_subsample = pd.read_csv('outputs/car_price/X_test_truth_av_subsample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3fd3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lead scoring test set\n",
    "lead_scoring_test_set = pd.read_csv(f'outputs/lead_scoring/test_set.csv')\n",
    "\n",
    "# Get and preprocess lead scoring test set\n",
    "ls_X_test = lead_scoring_test_set.copy().drop(columns=['converted'], axis=1)\n",
    "ls_X_test_pp = ls_data_pp.preprocess(ls_X_test)\n",
    "\n",
    "# Load lead scoring test subsample to initialize explainer that uses interventional approach\n",
    "ls_X_test_truth_av_subsample = pd.read_csv('outputs/lead_scoring/X_test_truth_av_subsample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d64a2",
   "metadata": {},
   "source": [
    "# Car Price Explainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69d19e",
   "metadata": {},
   "source": [
    "First, the adaptive random forest regressor is trained with test set and 10 model checkpoints are created. Then, the SHAP values are calculcated for each model checkpoint. The difference of the SHAP values is computed by substracting the ingested model predictions with the expected value. The difference should be close to 0 to indicate that the tree SHAP explainer is accurate in explaining model's predictions. In other words, a larger SHAP values difference indicates more inaccurate tree SHAP explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e032f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_shap_diff_rg(tree_explainer):\n",
    "    # Calculcate SHAP values\n",
    "    cp_shap_values = tree_explainer.shap_values(cp_X_test_pp, check_additivity=False)\n",
    "    # Original model's prediction output\n",
    "    true_y_pred = tree_explainer.model.predict(cp_X_test_pp)\n",
    "    # Sum of the SHAP values and the expected value\n",
    "    y_pred_calulated_fr_shap_val = tree_explainer.expected_value + cp_shap_values.sum(1)\n",
    "    # Get the biggest difference\n",
    "    largest_diff = np.abs(true_y_pred - y_pred_calulated_fr_shap_val).max()\n",
    "    return largest_diff\n",
    "\n",
    "def check_node_sample_weight(cur_arf_dict):\n",
    "    df = pd.DataFrame([], columns=['parent', 'left', 'right'])\n",
    "    node_count_df = pd.DataFrame([], columns=['count'])\n",
    "    node_id = -1\n",
    "\n",
    "    progress_unit = 1\n",
    "    desc = f'Checking Hoeffding trees'\n",
    "    with tqdm(total=len(cur_arf_dict[\"trees\"]), position=0, leave=True, desc=desc) as pbar:\n",
    "        for base_learner_no in range(len(cur_arf_dict[\"trees\"])):\n",
    "            node_count_df.loc[base_learner_no, :] = [len(cur_arf_dict[\"trees\"][base_learner_no][\"node_sample_weight\"])]\n",
    "            queue = []\n",
    "            # Separately track the node index position for both dictionaries\n",
    "            queue.append(0)\n",
    "\n",
    "            while len(queue) > 0:\n",
    "                ht_node_idx = queue.pop(0)\n",
    "                ht_node_idx = int(ht_node_idx)\n",
    "\n",
    "                # Retrieve the node_sample_weight from the dictionaries\n",
    "                ht_node_sw = cur_arf_dict[\"trees\"][base_learner_no][\"node_sample_weight\"][ht_node_idx]\n",
    "\n",
    "                # Add records to dataframe for debugging\n",
    "                node_id += 1\n",
    "\n",
    "                # Retrieve the left child index position from the dictionaries\n",
    "                ht_left_ch_idx = int(cur_arf_dict[\"trees\"][base_learner_no][\"children_left\"][ht_node_idx])\n",
    "\n",
    "                # Retrieve the right child index position from the dictionaries\n",
    "                ht_right_ch_idx = int(cur_arf_dict[\"trees\"][base_learner_no][\"children_right\"][ht_node_idx])\n",
    "\n",
    "                ht_left_node_sw = -1\n",
    "                ht_right_node_sw = -1\n",
    "\n",
    "                # Only enqueue if the child node is a branch node\n",
    "                if ht_left_ch_idx != -1:\n",
    "                    queue.append(ht_left_ch_idx)\n",
    "                    # Retrieve the left child node_sample_weight from the dictionaries\n",
    "                    ht_left_node_sw = cur_arf_dict[\"trees\"][base_learner_no][\"node_sample_weight\"][int(ht_left_ch_idx)]\n",
    "                if ht_right_ch_idx != -1:\n",
    "                    queue.append(ht_right_ch_idx)\n",
    "                    # Retrieve the right child node_sample_weight from the dictionaries\n",
    "                    ht_right_node_sw = cur_arf_dict[\"trees\"][base_learner_no][\"node_sample_weight\"][int(ht_right_ch_idx)]\n",
    "\n",
    "                df.loc[node_id, :] = [ht_node_sw, ht_left_node_sw, ht_right_node_sw]\n",
    "                # Update the progress bar.\n",
    "            pbar.update(progress_unit)\n",
    "\n",
    "    bool_index = (df['parent'] - df['left'] + df['right']) < 0\n",
    "    print('Invalid node_sample_weight:')\n",
    "    display(df[bool_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030e9a3",
   "metadata": {},
   "source": [
    "The result below shows the SHAP values difference for tree SHAP explainer that used `tree_path_dependent` approach. The tree SHAP explainer becomes more inaccurate as more samples are trained. Further analysis is conducted in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370f99db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing explainers: 100%|█████████████████| 11/11 [00:29<00:00,  2.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Largest difference in SHAP values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5149.22402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10833.002394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16265.587504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21541.62672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28325.577186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33378.069441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38454.312109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43884.79866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49323.235785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54954.740067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Largest difference in SHAP values\n",
       "0                                0.0\n",
       "1                         5149.22402\n",
       "2                       10833.002394\n",
       "3                       16265.587504\n",
       "4                        21541.62672\n",
       "5                       28325.577186\n",
       "6                       33378.069441\n",
       "7                       38454.312109\n",
       "8                        43884.79866\n",
       "9                       49323.235785\n",
       "10                      54954.740067"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment = 10\n",
    "\n",
    "df = pd.DataFrame([], columns=['Largest difference in SHAP values'])\n",
    "\n",
    "progress_unit = 1\n",
    "desc = f'Initializing explainers'\n",
    "with tqdm(total=increment+1, position=0, leave=True, desc=desc) as pbar:\n",
    "    # Load base model\n",
    "    with open('outputs/car_price/arf_rg.json', 'r') as f:\n",
    "        cp_arf_dict_serializable = json.load(f)\n",
    "    base_cp_arf_dict = deserialize_arf(cp_arf_dict_serializable)\n",
    "    # Initialize tree SHAP explainer\n",
    "    cp_exp_tree_path_dependent = shap.TreeExplainer(\n",
    "        model = base_cp_arf_dict, \n",
    "        feature_perturbation = 'tree_path_dependent', \n",
    "    )\n",
    "    # Get the largest SHAP difference\n",
    "    df.loc[0, :] = [get_largest_shap_diff_rg(cp_exp_tree_path_dependent)]\n",
    "    # Update progress bar\n",
    "    pbar.update(progress_unit)\n",
    "    \n",
    "    for idx in range(1, increment+1):\n",
    "        # Load the model at ith checkpoint\n",
    "        with open(f'outputs/explainer_validation/car_price/arf_rg_{idx}.json', 'r') as f:\n",
    "            cp_arf_dict_serializable = json.load(f)\n",
    "        cp_arf_dict = deserialize_arf(cp_arf_dict_serializable)\n",
    "        # Initialize tree SHAP explainer\n",
    "        cp_exp_tree_path_dependent = shap.TreeExplainer(\n",
    "            model = cp_arf_dict, \n",
    "            feature_perturbation = 'tree_path_dependent', \n",
    "        )\n",
    "        # Get the largest SHAP difference\n",
    "        df.loc[idx, :] = [get_largest_shap_diff_rg(cp_exp_tree_path_dependent)]\n",
    "        # Update the progress bar.\n",
    "        pbar.update(progress_unit)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2db762",
   "metadata": {},
   "source": [
    "By analyzing the results below, it turned out that the Hoeffding tree regressor did not update `node_sample_weight` on the parent node. Tree SHAP explainer expects that for every parent node *i*, the `node_sample_weight` of the left and right child of parent node *i* must always be smaller than parent node *i* itself. Since the River only update `node_sample_weight` at the leaf node, the expectation is broken. With the expectation broken, the SHAP values calculation will be inaccurate since the `tree_path_dependent` approach calculates SHAP values by using `node_sample_weight`. Therefore, the River developer should give the option to update the `node_sample_weight` to ensure compatibility and interoperability of River models with other Python libraries like SHAP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a200e",
   "metadata": {},
   "source": [
    "The code below checks the expectation on the pre-trained car price model. The expectation holds true since the tree weights are transferred from the Scikit-learn random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18802f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking Hoeffding trees: 100%|████████████████| 15/15 [00:02<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid node_sample_weight:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [parent, left, right]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_node_sample_weight(base_cp_arf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf42ce",
   "metadata": {},
   "source": [
    "The result below checks the expectation on the pre-trained car price model that is trained with new samples. The expectation does not hold true since the Hoeffding tree regressor did not update `node_sample_weight` on the parent node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c2b367",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking Hoeffding trees: 100%|████████████████| 15/15 [00:04<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid node_sample_weight:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>74.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>79.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>64.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>73.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>86.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463</th>\n",
       "      <td>163.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>72.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8491</th>\n",
       "      <td>562.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8555</th>\n",
       "      <td>166.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>61.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     parent   left right\n",
       "53     74.0  115.0  12.0\n",
       "72     79.0  123.0   8.0\n",
       "82     64.0   91.0   7.0\n",
       "155    73.0  106.0  18.0\n",
       "165    86.0  110.0  12.0\n",
       "...     ...    ...   ...\n",
       "8463  163.0  206.0  22.0\n",
       "8471   72.0  122.0  18.0\n",
       "8491  562.0  596.0  31.0\n",
       "8555  166.0  184.0   7.0\n",
       "8573   61.0   83.0  20.0\n",
       "\n",
       "[416 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f'outputs/explainer_validation/car_price/arf_rg_{10}.json', 'r') as f:\n",
    "    cp_arf_dict_serializable = json.load(f)\n",
    "cp_arf_dict = deserialize_arf(cp_arf_dict_serializable)\n",
    "check_node_sample_weight(cp_arf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e2152",
   "metadata": {},
   "source": [
    "Fortunately, the model predictions can still be explained using tree SHAP explainer with the `interventional` approach instead of `tree_path_dependent` approach. The result below shows that the SHAP value difference are consistent in all the model checkpoints. The differences are negligible since the car price prediction values are in thousands and not sensitive to SHAP value differences that are less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4962b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing explainers: 100%|█████████████████| 11/11 [00:35<00:00,  3.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Largest difference in SHAP values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Largest difference in SHAP values\n",
       "0                           0.010849\n",
       "1                           0.014626\n",
       "2                           0.009889\n",
       "3                           0.010842\n",
       "4                            0.01027\n",
       "5                           0.008185\n",
       "6                           0.007507\n",
       "7                           0.008405\n",
       "8                           0.009215\n",
       "9                           0.007914\n",
       "10                          0.010849"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment = 10\n",
    "\n",
    "df = pd.DataFrame([], columns=['Largest difference in SHAP values'])\n",
    "\n",
    "progress_unit = 1\n",
    "desc = f'Initializing explainers'\n",
    "with tqdm(total=increment+1, position=0, leave=True, desc=desc) as pbar:\n",
    "    # Load base model\n",
    "    with open('outputs/car_price/arf_rg.json', 'r') as f:\n",
    "        cp_arf_dict_serializable = json.load(f)\n",
    "    base_cp_arf_dict = deserialize_arf(cp_arf_dict_serializable)\n",
    "    # Initialize tree SHAP explainer\n",
    "    cp_exp_interventional = shap.TreeExplainer(\n",
    "        model = cp_arf_dict, \n",
    "        feature_perturbation = 'interventional', \n",
    "        data = cp_X_test_truth_av_subsample\n",
    "    )\n",
    "    # Get the largest SHAP difference\n",
    "    df.loc[0, :] = [get_largest_shap_diff_rg(cp_exp_interventional)]\n",
    "    # Update progress bar\n",
    "    pbar.update(progress_unit)\n",
    "    \n",
    "    for idx in range(1, increment+1):\n",
    "        # Load the model at ith checkpoint\n",
    "        with open(f'outputs/explainer_validation/car_price/arf_rg_{idx}.json', 'r') as f:\n",
    "            cp_arf_dict_serializable = json.load(f)\n",
    "        cp_arf_dict = deserialize_arf(cp_arf_dict_serializable)\n",
    "        # Initialize tree SHAP explainer\n",
    "        cp_exp_interventional = shap.TreeExplainer(\n",
    "            model = cp_arf_dict, \n",
    "            feature_perturbation = 'interventional', \n",
    "            data = cp_X_test_truth_av_subsample\n",
    "        )\n",
    "        # Get the largest SHAP difference\n",
    "        df.loc[idx, :] = [get_largest_shap_diff_rg(cp_exp_interventional)]\n",
    "        # Update progress bar\n",
    "        pbar.update(progress_unit)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b8aa2",
   "metadata": {},
   "source": [
    "# Lead Scoring Explainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06805da9",
   "metadata": {},
   "source": [
    "The same experiment is also conducted for adaptive random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35953e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_shap_diff_cf(tree_explainer):\n",
    "    # Calculcate SHAP values\n",
    "    ls_shap_values = tree_explainer.shap_values(ls_X_test_pp, check_additivity=False)\n",
    "    # Original model's prediction output\n",
    "    true_y_pred = tree_explainer.model.predict(ls_X_test_pp)\n",
    "    # Sum of the SHAP values and the expected value\n",
    "    y_pred_calulated_fr_shap_val = \\\n",
    "    tree_explainer.expected_value[:, np.newaxis] + \\\n",
    "    np.sum(np.array(ls_shap_values), axis=-1) \n",
    "    # Get the biggest difference\n",
    "    largest_diff = np.abs(true_y_pred - y_pred_calulated_fr_shap_val.T).flatten().max()\n",
    "    return largest_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a4614",
   "metadata": {},
   "source": [
    "The result below shows the SHAP values difference for tree SHAP explainer that used `tree_path_dependent` approach. The tree SHAP explainer becomes more inaccurate as more samples are trained. The differences are significant since the model outputs prediction probabilities ranging from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2568cc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing explainers: 100%|█████████████████| 11/11 [00:02<00:00,  5.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Largest difference in SHAP values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.132005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0855889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0440363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0764652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0929509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.137198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.148903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.167896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.213597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Largest difference in SHAP values\n",
       "0                                0.0\n",
       "1                           0.132005\n",
       "2                           0.137843\n",
       "3                          0.0855889\n",
       "4                          0.0440363\n",
       "5                          0.0764652\n",
       "6                          0.0929509\n",
       "7                           0.137198\n",
       "8                           0.148903\n",
       "9                           0.167896\n",
       "10                          0.213597"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment = 10\n",
    "\n",
    "df = pd.DataFrame([], columns=['Largest difference in SHAP values'])\n",
    "\n",
    "progress_unit = 1\n",
    "desc = f'Initializing explainers'\n",
    "with tqdm(total=increment+1, position=0, leave=True, desc=desc) as pbar:\n",
    "    # Load base model\n",
    "    with open('outputs/lead_scoring/arf_cf.json', 'r') as f:\n",
    "        ls_arf_dict_serializable = json.load(f)\n",
    "    base_ls_arf_dict = deserialize_arf(ls_arf_dict_serializable)\n",
    "    # Initialize tree SHAP explainer\n",
    "    ls_exp_tree_path_dependent = shap.TreeExplainer(\n",
    "        model = base_ls_arf_dict, \n",
    "        feature_perturbation = 'tree_path_dependent', \n",
    "    )\n",
    "    # Get the largest SHAP difference\n",
    "    df.loc[0, :] = [get_largest_shap_diff_cf(ls_exp_tree_path_dependent)]\n",
    "    # Update progress bar\n",
    "    pbar.update(progress_unit)\n",
    "    \n",
    "    for idx in range(1, increment+1):\n",
    "        # Load the model at ith checkpoint\n",
    "        with open(f'outputs/explainer_validation/lead_scoring/arf_cf_{idx}.json', 'r') as f:\n",
    "            ls_arf_dict_serializable = json.load(f)\n",
    "        ls_arf_dict = deserialize_arf(ls_arf_dict_serializable)\n",
    "        # Initialize tree SHAP explainer\n",
    "        ls_exp_tree_path_dependent = shap.TreeExplainer(\n",
    "            model = ls_arf_dict, \n",
    "            feature_perturbation = 'tree_path_dependent', \n",
    "        )\n",
    "        # Get the largest SHAP difference\n",
    "        df.loc[idx, :] = [f'{get_largest_shap_diff_cf(ls_exp_tree_path_dependent):4g}']\n",
    "        # Update the progress bar.\n",
    "        pbar.update(progress_unit)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b5d04",
   "metadata": {},
   "source": [
    "By analyzing the results below, it turned out that the Hoeffding tree classifier also did not update `node_sample_weight` on the parent node. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848aeba",
   "metadata": {},
   "source": [
    "The code below checks the expectation on the pre-trained lead scoring model. The expectation holds true since the tree weights are directly transferred from the Scikit-learn random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdf35e8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking Hoeffding trees: 100%|████████████████| 20/20 [00:00<00:00, 57.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid node_sample_weight:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [parent, left, right]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_node_sample_weight(base_ls_arf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d7590",
   "metadata": {},
   "source": [
    "The result below checks the expectation on the pre-trained lead scoring model that is trained with new samples. The expectation does not hold true since the Hoeffding tree classifier did not update `node_sample_weight` on the parent node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea927dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking Hoeffding trees: 100%|████████████████| 20/20 [00:00<00:00, 32.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid node_sample_weight:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>165.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>446.0</td>\n",
       "      <td>875.351869</td>\n",
       "      <td>233.648131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>188.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>114.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>199.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>187.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>270.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>941.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>578.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>138.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     parent        left       right\n",
       "8     165.0       383.0        15.0\n",
       "47    446.0  875.351869  233.648131\n",
       "88    188.0       420.0        25.0\n",
       "89    114.0       221.0        13.0\n",
       "93    199.0       456.0       111.0\n",
       "...     ...         ...         ...\n",
       "1285  187.0       389.0       142.0\n",
       "1287  270.0       548.0       134.0\n",
       "1304  941.0       963.0         2.0\n",
       "1315  578.0       710.0         2.0\n",
       "1349  138.0       364.0        16.0\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(f'outputs/explainer_validation/lead_scoring/arf_cf_{10}.json', 'r') as f:\n",
    "    ls_arf_dict_serializable = json.load(f)\n",
    "ls_arf_dict = deserialize_arf(ls_arf_dict_serializable)\n",
    "check_node_sample_weight(ls_arf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e23825f",
   "metadata": {},
   "source": [
    "Fortunately, the model predictions can still be explained using tree SHAP explainer with the `interventional` approach instead of `tree_path_dependent` approach. The result below shows that the SHAP value difference are consistent in all the model checkpoints. The differences are negligible since the SHAP value differences are less than 1e-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142b033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing explainers: 100%|█████████████████| 11/11 [00:23<00:00,  2.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Largest difference in SHAP values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.41219e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.38361e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.46521e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.92897e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.93313e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.8947e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.07608e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.78671e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.11324e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.40809e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Largest difference in SHAP values\n",
       "0                                0.0\n",
       "1                        2.41219e-08\n",
       "2                        2.38361e-08\n",
       "3                        2.46521e-08\n",
       "4                        1.92897e-08\n",
       "5                        1.93313e-08\n",
       "6                         1.8947e-08\n",
       "7                        2.07608e-08\n",
       "8                        1.78671e-08\n",
       "9                        2.11324e-08\n",
       "10                       2.40809e-08"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment = 10\n",
    "\n",
    "df = pd.DataFrame([], columns=['Largest difference in SHAP values'])\n",
    "\n",
    "progress_unit = 1\n",
    "desc = f'Initializing explainers'\n",
    "with tqdm(total=increment+1, position=0, leave=True, desc=desc) as pbar:\n",
    "    # Load base model\n",
    "    with open('outputs/lead_scoring/arf_cf.json', 'r') as f:\n",
    "        ls_arf_dict_serializable = json.load(f)\n",
    "    base_ls_arf_dict = deserialize_arf(ls_arf_dict_serializable)\n",
    "    # Initialize tree SHAP explainer\n",
    "    ls_exp_interventional = shap.TreeExplainer(\n",
    "        model = ls_arf_dict, \n",
    "        feature_perturbation = 'interventional', \n",
    "        data = ls_X_test_truth_av_subsample\n",
    "    )\n",
    "    # Get the largest SHAP difference\n",
    "    df.loc[0, :] = [get_largest_shap_diff_cf(ls_exp_interventional)]\n",
    "    # Update progress bar\n",
    "    pbar.update(progress_unit)\n",
    "    \n",
    "    for idx in range(1, increment+1):\n",
    "        # Load the model at ith checkpoint\n",
    "        with open(f'outputs/explainer_validation/lead_scoring/arf_cf_{idx}.json', 'r') as f:\n",
    "            ls_arf_dict_serializable = json.load(f)\n",
    "        ls_arf_dict = deserialize_arf(ls_arf_dict_serializable)\n",
    "        # Initialize tree SHAP explainer\n",
    "        ls_exp_interventional = shap.TreeExplainer(\n",
    "            model = ls_arf_dict, \n",
    "            feature_perturbation = 'interventional', \n",
    "            data = ls_X_test_truth_av_subsample\n",
    "        )\n",
    "        # Get the largest SHAP difference\n",
    "        df.loc[idx, :] = [f'{get_largest_shap_diff_cf(ls_exp_interventional):4g}']\n",
    "        # Update progress bar\n",
    "        pbar.update(progress_unit)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d2d03",
   "metadata": {},
   "source": [
    "Thank you for reading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SHAP Env)",
   "language": "python",
   "name": "arf_conda_exp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
